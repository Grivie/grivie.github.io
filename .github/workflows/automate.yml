name: Grivie Scrapers

on:
  schedule:
    - cron: '0 * * * *'
  workflow_dispatch:

jobs:
  scrape-and-commit:
    name: "Sedang Melakukan Scraping dan Simpan Data"
    runs-on: ubuntu-latest

    steps:
      - name: Check out source repository
        uses: actions/checkout@v4
        with:
          path: source-repo

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install Chromium Browser
        run: sudo apt-get update && sudo apt-get install -y chromium-browser

      - name: Install Python dependencies
        run: |
          cd source-repo
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Run scraper script
        run: |
          cd source-repo
          python scraper.py

      - name: Check out data repository
        uses: actions/checkout@v4
        with:
          repository: username/repo-data
          path: data-repo
          token: ${{ secrets.ACTIONS_PAT }}

      - name: Move scraped file to data repository
        run: mv source-repo/product.json data-repo/product.json

      - name: Commit and push to data repository
        run: |
          cd data-repo
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"
          git add product.json
          if ! git diff --staged --quiet; then
            git commit -m "Update: hourly product data sync"
            git push
          else
            echo "No changes to commit."
          fi
